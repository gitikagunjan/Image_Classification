{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "554122cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (19, 1)\n",
      "y:  [[1. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize(X):\n",
    "    '''\n",
    "    function to normalize feature matrix, X\n",
    "    '''\n",
    "    mins = np.min(X, axis = 0)\n",
    "    maxs = np.max(X, axis = 0)\n",
    "    rng = maxs - mins\n",
    "    norm_X = 1 - ((maxs - X)/rng)\n",
    "    return norm_X\n",
    "\n",
    "x = np.array([0,1,1,1,1,1,1,0,0,0,1,0,1,1,0,0,0,0,1])\n",
    "x= np.array(x).reshape(19,1)\n",
    "#y = np.ones(x.shape[0])\n",
    "X = normalize(x[:, :-1])\n",
    "y = np.hstack((np.matrix(np.ones(x.shape[0])).T, x))\n",
    "#z = np.zeros(y.shape[1])\n",
    "print('x shape: ' ,x.shape)\n",
    "print('y: ' , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35a9c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============:  2\n",
      "=====X_tmp:  [[1 1 1 1]\n",
      " [2 2 2 2]]\n",
      "======XXX_tmp:  [ 0.217022    0.52032449 -0.19988563  0.10233257]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "X_tmp = np.array([[1,1,1,1],\n",
    "                [2,2,2,2]])\n",
    "\n",
    "print('============: ', X_tmp.shape[0])\n",
    "XXX_tmp = np.random.rand(X_tmp.shape[1]).reshape(-1,)-0.2\n",
    "\n",
    "\n",
    "#y_tmp = np.array([0,1,0,1,0])\n",
    "\n",
    "#w_tmp = np.random.rand(X_tmp.shape[1]).reshape(-1,)-0.5\n",
    "\n",
    "print('=====X_tmp: ', X_tmp)\n",
    "#print('======w_tmp: ' , w_tmp)\n",
    "print('======XXX_tmp: ' ,XXX_tmp)\n",
    "\n",
    "b_tmp = 0.5\n",
    "lambda_tmp = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67f7d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# example dataset:\n",
    "# dataset = [\n",
    "#     [4, 82, 1],\n",
    "#     [3, 80, 0],\n",
    "#     [2.5, 75, 0],\n",
    "#     [3.4, 90, 1],\n",
    "#     [4.2, 88, 1],\n",
    "#     [5, 92, 1],\n",
    "#     [2.7, 99, 0],\n",
    "#     [3.3, 85, 0],\n",
    "#     [4.2, 72, 0],\n",
    "#     [3.6, 80, 0],\n",
    "#     [2.9, 85, 0],\n",
    "#     [3.9, 85, 1],\n",
    "#     [4.5, 99, 1],\n",
    "#     [4.7, 90, 1],\n",
    "#     [4.6, 80, 1],\n",
    "#     [4.6, 75, 0],\n",
    "#     [3.4, 64, 0],\n",
    "# ]\n",
    "\n",
    "# each inner array (datapoint) represents one student.\n",
    "# datapoint[0] = GPA\n",
    "# datapoint[1] = exam score\n",
    "# datapoint[2] = whether student was admitted. 1 = yes. 0 = no.\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.alpha = 0.002  # alpha is \"learning rate\"\n",
    "\n",
    "    # get new theta according to gradient ascent formula\n",
    "    def get_theta(self, theta):\n",
    "        num_params = len(self.dataset[0])\n",
    "        new_gradients = [0] * num_params\n",
    "        m = len(self.dataset)\n",
    "        for i in range(0, len(self.dataset)):\n",
    "            predicted = self.get_prediction(theta, self.dataset[i])\n",
    "            actual = self.dataset[i][-1]\n",
    "            for j in range(0, num_params):\n",
    "                x_j = 1 if j == 0 else self.dataset[i][j - 1]\n",
    "                new_gradients[j] += (actual - predicted) * x_j\n",
    "                # new_gradients[j] += (predicted - actual) * x_j\n",
    "\n",
    "        new_theta = [0] * num_params\n",
    "        for j in range(0, num_params):\n",
    "            new_theta[j] = theta[j] + self.alpha * (1/m) * new_gradients[j]\n",
    "\n",
    "        return new_theta\n",
    "\n",
    "    # uses sigmoid function. Outputs a number from 0 to 1, which denotes probability\n",
    "    def get_prediction(self, theta, data_point):\n",
    "        inner_val = self.matrix_dot_product(theta, data_point)\n",
    "        probability = 1 / (1 + math.exp(- 1 * inner_val))\n",
    "        return probability\n",
    "\n",
    "    def matrix_dot_product(self, theta, data_point):\n",
    "        values = [0]*len(data_point)\n",
    "        for i in range(0, len(values)):\n",
    "            values[i] = 1 if i == 0 else data_point[i-1]\n",
    "\n",
    "        result = np.dot(theta, values)\n",
    "        return result\n",
    "\n",
    "    def calc_max_likelihood_estimate(self, theta):\n",
    "        sum = 0\n",
    "        for i in range(0, len(self.dataset)):\n",
    "            predicted = self.get_prediction(theta, self.dataset[i])\n",
    "            actual = self.dataset[i][-1]\n",
    "            increment = actual * math.log(predicted) + (1 - actual) * math.log(1 - predicted)\n",
    "            sum += increment\n",
    "\n",
    "        return sum\n",
    "\n",
    "    def iterate(self):\n",
    "        num_iteration = 0\n",
    "        current_probability = None\n",
    "        # current_theta = [-1] * len(self.dataset[0])  # initialize to 0\n",
    "        current_theta = [-109.99, 10.655, 0.821]\n",
    "\n",
    "        while num_iteration < 1000:\n",
    "            if num_iteration % 10 == 0:\n",
    "                print('current iteration: ', num_iteration)\n",
    "                print('current probability: ', current_probability)\n",
    "                print('current theta: ', current_theta)\n",
    "            new_probability = self.calc_max_likelihood_estimate(current_theta)\n",
    "            current_probability = new_probability\n",
    "            new_theta = self.get_theta(current_theta)\n",
    "            current_theta = new_theta\n",
    "            num_iteration += 1\n",
    "\n",
    "        print(f'After {num_iteration}, total probability is {current_probability}. Theta is {current_theta}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a0ff49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length num_params: 3\n",
      "length of m:  17\n",
      "gradient : [0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'\\n    for i in range(0, len(dataset)):\\n        predicted = self.get_prediction(theta, dataset[i])\\n        actual = dataset[i][-1]\\n        print('actual: ', actual)\\n        for j in range(0, num_params):\\n            x_j = 1 if j == 0 else dataset[i][j - 1]\\n            new_gradients[j] += (actual - predicted) * x_j\\n            # new_gradients[j] += (predicted - actual) * x_j\\n\\n    new_theta = [0] * num_params\\n    for j in range(0, num_params):\\n        new_theta[j] = theta[j] + self.alpha * (1/m) * new_gradients[j]\\n\\n    return new_theta\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # get new theta according to gradient ascent formula\n",
    "dataset = ([[4, 82, 1],\n",
    "    [3, 80, 0],\n",
    "    [2.5, 75, 0],\n",
    "    [3.4, 90, 1],\n",
    "    [4.2, 88, 1],\n",
    "    [5, 92, 1],\n",
    "    [2.7, 99, 0],\n",
    "    [3.3, 85, 0],\n",
    "    [4.2, 72, 0],\n",
    "    [3.6, 80, 0],\n",
    "    [2.9, 85, 0],\n",
    "    [3.9, 85, 1],\n",
    "    [4.5, 99, 1],\n",
    "    [4.7, 90, 1],\n",
    "    [4.6, 80, 1],\n",
    "    [4.6, 75, 0],\n",
    "    [3.4, 64, 0],\n",
    " ])\n",
    "\n",
    "num_params = len(dataset[0])\n",
    "print('length num_params:', num_params)\n",
    "new_gradients = [0] * num_params\n",
    "m = len(dataset)\n",
    "print('length of m: ' , m)\n",
    "print('gradient :', new_gradients)\n",
    "\n",
    "def matrix_dot_product(self, theta, data_point):\n",
    "    values = [0]*len(data_point)\n",
    "    for i in range(0, len(values)):\n",
    "        values[i] = 1 if i == 0 else data_point[i-1]\n",
    "\n",
    "        result = np.dot(theta, values)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ff1637ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==feature [1 0 1 1 1]\n",
      "==label [0, 1, 1, 0, 1]\n",
      "probability of feature =1 | given labal = 1:  0.6666666666666666\n",
      "probability of feature =0 | given labal = 1:  0.3333333333333333\n",
      "======: [0.3333333333333333, 0.6666666666666666]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def estimate(feature,label):\n",
    "    lcount_0 = 0\n",
    "    lcount_1 = 0\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        if(label[i] == 0):\n",
    "            lcount_0 += 1\n",
    "        elif(label[i] == 1):\n",
    "            lcount_1 += 1\n",
    "\n",
    "\n",
    "    count_f1_l1 = 0\n",
    "    count_f0_l1 = 0\n",
    "    for i in range(len(feature)):\n",
    "        if(feature[i] == 0 and label[i] == 1):\n",
    "            count_f0_l1 += 1\n",
    "        elif(feature[i] == 1 and label[i] == 1):\n",
    "            count_f1_l1 += 1\n",
    "    \n",
    "    Pf0_l1 = count_f0_l1 / lcount_1\n",
    "    Pf1_l1 = count_f1_l1 /lcount_1\n",
    "\n",
    "\n",
    "\n",
    "    #print('probability of feature =1 | given labal = 1: ', pf1_l1)\n",
    "    #print('probability of feature =0 | given labal = 1: ', pf0_l1)\n",
    "    a = [pf0_l1,pf1_l1]\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    feature= np.array([1,0,1,1,1])\n",
    "    label= ([0,1,1,0,1])\n",
    "    print('==feature' , feature)\n",
    "    print('==label' , label)\n",
    "    \n",
    "    x = estimate(feature,label)\n",
    "    print('======:' , x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30070864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
